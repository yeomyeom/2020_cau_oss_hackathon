{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hackathon_team11.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "1AosAX9DXOlc",
        "67lwEXhUqys1",
        "A-YjppJpXBO9",
        "4aPbgI-c-Kj8"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yeomyeom/2020_cau_oss_hackathon/blob/master/hackathon_team11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "67lwEXhUqys1"
      },
      "source": [
        "# **1. 초기 환경 설정**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ms5PBBJ1qSC6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "outputId": "b70ca0dc-5d58-406e-d6ad-4982c58c09e6"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals, unicode_literals\n",
        "\n",
        "# tensorflow와 tf.keras 및 관련 라이브러리 임포트\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.utils import np_utils\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# 데이터셋 다운로드\n",
        "check = !if [ -d 'dataset/' ]; then echo \"1\" ; else echo \"0\"; fi\n",
        "if (check[0] is '0' ):\n",
        "  !mkdir dataset\n",
        "  !wget 'https://www.itl.nist.gov/iaui/vip/cs_links/EMNIST/matlab.zip'\n",
        "  !unzip matlab.zip -d /content/dataset\n",
        "\n",
        "# 데이터셋 로드\n",
        "from scipy import io as spio\n",
        "emnist = spio.loadmat(\"/content/dataset/matlab/emnist-balanced.mat\")\n",
        "\n",
        "x_train = emnist[\"dataset\"][0][0][0][0][0][0]\n",
        "y_train = emnist[\"dataset\"][0][0][0][0][0][1]\n",
        "\n",
        "x_test = emnist[\"dataset\"][0][0][1][0][0][0]\n",
        "y_test = emnist[\"dataset\"][0][0][1][0][0][1]\n",
        "\n",
        "# # 분류를 위해 클래스 벡터를 바이너리 매트릭스로 변환\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "\n",
        "# 데이터 28x28 이미지화\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32')\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32')\n",
        "\n",
        "# 총 클래스 개수\n",
        "num_classes = y_test.shape[1]\n",
        "input_shape = x_test.shape[1:]"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-29 07:21:36--  https://www.itl.nist.gov/iaui/vip/cs_links/EMNIST/matlab.zip\n",
            "Resolving www.itl.nist.gov (www.itl.nist.gov)... 129.6.13.51, 2610:20:6b01:4::36\n",
            "Connecting to www.itl.nist.gov (www.itl.nist.gov)|129.6.13.51|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 743900280 (709M) [application/zip]\n",
            "Saving to: ‘matlab.zip’\n",
            "\n",
            "matlab.zip          100%[===================>] 709.44M  15.5MB/s    in 47s     \n",
            "\n",
            "2020-08-29 07:22:24 (15.0 MB/s) - ‘matlab.zip’ saved [743900280/743900280]\n",
            "\n",
            "Archive:  matlab.zip\n",
            "  inflating: /content/dataset/matlab/emnist-balanced.mat  \n",
            "  inflating: /content/dataset/matlab/emnist-byclass.mat  \n",
            "  inflating: /content/dataset/matlab/emnist-bymerge.mat  \n",
            "  inflating: /content/dataset/matlab/emnist-digits.mat  \n",
            "  inflating: /content/dataset/matlab/emnist-letters.mat  \n",
            "  inflating: /content/dataset/matlab/emnist-mnist.mat  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "A-YjppJpXBO9"
      },
      "source": [
        "# **2. 데이터 전처리**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QZ9KWTBP6AI1",
        "colab": {}
      },
      "source": [
        "# 데이터 전처리 (예: normalization)\n",
        "x_train_after = x_train / 255.0\n",
        "x_test_after = x_test / 255.0"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXhkhvtkQF50",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "start = 100\n",
        "finish = start + 25\n",
        "for i in range(start, finish):\n",
        "  plt.subplot(5,5,i+1 - start)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.grid(False)\n",
        "  #plt.imshow(y_train[i], cmap=plt.cm.binary)\n",
        "  plt.imshow((tf.squeeze(x_train_after[i])))\n",
        "plt.show"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1AosAX9DXOlc"
      },
      "source": [
        "# **0. 해커톤 진행 주의사항**\n",
        "\n",
        "**1)  개발 관련 주의사항**\n",
        "*   [1. 초기 환경 설정]은 절대 수정하지 말 것\n",
        "*   모든 구현은 [2. 데이터 전처리] 및 [3.모델 생성]에서만 진행\n",
        "*   [4. 모델 저장]에서 team_name 변수 변경 (예.`team_name = 'team01'`)\n",
        " *    트레이닝 중간에 checkpoint를 활용하여 모델을 저장한 경우에도 파일 이름 양식 통일 필수\n",
        "*   Colab 사용중 실수로 데이터 손실이 발생할 수도 있으니 중간 결과값을 github에 업로드 \n",
        " *    \"런타임->모든 런타임 재설정\"은 절대 누르지 말 것 (저장한 모델 데이터가 모두 삭제됨)\n",
        "*   효율적인 구현 및 테스팅을 위해 GPU 가속 기능 활성화\n",
        " *    \"런타임 -> 런타임 유형변경 -> 하드웨어 가속기 -> GPU 설정\"\n",
        "*   주석을 최대한 자세히 작성\n",
        "*   Keras API 관련하여 [Keras Documentation](https://keras.io/) 참조\n",
        "\n",
        "**2) 제출 관련 주의사항**\n",
        "*  제출물\n",
        " *  소스코드 (hackathon_teamXX.ipynb)\n",
        " *  컴파일된 모델 파일 (model_entire_teamXX.h5)\n",
        " *  모델 발표 자료 \n",
        "* 제출 기한: **오후 5시 (단, 발표자료는 11시)**\n",
        "* 제출 방법: [GitHub README](https://github.com/cauosshackathonta/2020_cau_oss_hackathon/) 참조\n",
        "\n",
        " \n",
        "**3) 평가 관련 주의사항**\n",
        "*  모델 성능 = 테스트 데이터 셋 분류 정확도\n",
        " *  model.evaluate(x_test, y_test)\n",
        "*  제출된 모델들의 테스트 데이터 셋 분류 정확도를 기준으로 수상작 결정\n",
        "*  수상 후보들에 대해서는 소스코드를 기반으로 모델 재검증 \n",
        " \n",
        "**4) 수상 실격 사유**\n",
        "*  유사한 소스코드 or 알고리즘이 적발될 경우\n",
        "*  소스코드와 제출된 모델이 상이한 경우\n",
        "*  개발 관련 주의사항을 지키지 않은 경우\n",
        " *  예: [초기 환경 설정]을 수정한 경우\n",
        "*  데이터 셋을 변조한 경우\n",
        " *  예. 테스트 데이터 셋을 트레이닝 데이터 셋에 포함하여 모델 생성 \n",
        "*  주석이 소스코드와 맞지 않거나 미비할 경우\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "v-lo-O1yiFpY"
      },
      "source": [
        "# **3. 모델 생성**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DZP4eRmRqgRp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "58abe8c3-7d2e-4685-e1f1-83e473f894ab"
      },
      "source": [
        "from keras.layers import BatchNormalization, Dropout\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "EPOCH = 150\n",
        "\n",
        "# 순차 모델 생성 (가장 기본구조)\n",
        "model = keras.Sequential()\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(100, (5,5), input_shape = (28,28,1), activation='relu', \n",
        "                 kernel_initializer='he_normal'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Conv2D(80, (4,4), activation='relu', \n",
        "                 kernel_initializer='he_normal'))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(50, (3,3), activation='relu', \n",
        "                 kernel_initializer='he_normal'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Conv2D(50, (3,3), activation='relu', \n",
        "                 kernel_initializer='he_normal'))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(256, activation='relu', kernel_initializer='he_normal'))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Output layer: fully-connected layer \n",
        "# (# of inputs = 64, # of outputs = 47, actication fuction = softmax)\n",
        "model.add(keras.layers.Dense(num_classes, activation=tf.nn.softmax))\n",
        "# 모델 컴파일\n",
        "# optimizer: 모델을 업데이트 하는 방식\n",
        "# loss: 모델의 정확도를 판단하는 방식\n",
        "# metrics: 트레이닝 및 테스팅 성능 모니터링을 위한 평가지표\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# 체크포인트 생성\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath='/content/checkpoint_entire_best.h5', monitor='val_accuracy', verbose=1, save_weight_only=False, save_best_only=True, mode='auto')\n",
        "\n",
        "# 모델 트레이닝\n",
        "# batch_size: 전체 데이터셋 중 몇개씩 학습시킬 것인지\n",
        "# epoch: 학습에 전체 데이터셋이 총 몇번 이용될 것인지\n",
        "# shuffle: 학습전에 트레이닝 데이터셋을 랜덤하게 섞을 것인지\n",
        "# validation_data: 중간 성능 검증에 사용할 data set\n",
        "model.fit(x_train_after, y_train, batch_size = 128, epochs = EPOCH, shuffle=True, callbacks=[cp_callback], validation_data=(x_test_after, y_test))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "882/882 [==============================] - ETA: 0s - loss: 1.0420 - accuracy: 0.6901\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.83043, saving model to /content/checkpoint_entire_best.h5\n",
            "882/882 [==============================] - 12s 14ms/step - loss: 1.0420 - accuracy: 0.6901 - val_loss: 0.5009 - val_accuracy: 0.8304\n",
            "Epoch 2/150\n",
            "880/882 [============================>.] - ETA: 0s - loss: 0.5071 - accuracy: 0.8279\n",
            "Epoch 00002: val_accuracy improved from 0.83043 to 0.85090, saving model to /content/checkpoint_entire_best.h5\n",
            "882/882 [==============================] - 12s 14ms/step - loss: 0.5069 - accuracy: 0.8280 - val_loss: 0.4155 - val_accuracy: 0.8509\n",
            "Epoch 3/150\n",
            "878/882 [============================>.] - ETA: 0s - loss: 0.4347 - accuracy: 0.8480\n",
            "Epoch 00003: val_accuracy improved from 0.85090 to 0.86452, saving model to /content/checkpoint_entire_best.h5\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.4349 - accuracy: 0.8480 - val_loss: 0.3828 - val_accuracy: 0.8645\n",
            "Epoch 4/150\n",
            "882/882 [==============================] - ETA: 0s - loss: 0.3975 - accuracy: 0.8587\n",
            "Epoch 00004: val_accuracy improved from 0.86452 to 0.86670, saving model to /content/checkpoint_entire_best.h5\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.3975 - accuracy: 0.8587 - val_loss: 0.3688 - val_accuracy: 0.8667\n",
            "Epoch 5/150\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.3746 - accuracy: 0.8656\n",
            "Epoch 00005: val_accuracy improved from 0.86670 to 0.86856, saving model to /content/checkpoint_entire_best.h5\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.3745 - accuracy: 0.8656 - val_loss: 0.3666 - val_accuracy: 0.8686\n",
            "Epoch 6/150\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.3574 - accuracy: 0.8708\n",
            "Epoch 00006: val_accuracy improved from 0.86856 to 0.87787, saving model to /content/checkpoint_entire_best.h5\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.3575 - accuracy: 0.8708 - val_loss: 0.3437 - val_accuracy: 0.8779\n",
            "Epoch 7/150\n",
            "879/882 [============================>.] - ETA: 0s - loss: 0.3409 - accuracy: 0.8754\n",
            "Epoch 00007: val_accuracy improved from 0.87787 to 0.88112, saving model to /content/checkpoint_entire_best.h5\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.3409 - accuracy: 0.8754 - val_loss: 0.3349 - val_accuracy: 0.8811\n",
            "Epoch 8/150\n",
            "878/882 [============================>.] - ETA: 0s - loss: 0.3310 - accuracy: 0.8787\n",
            "Epoch 00008: val_accuracy improved from 0.88112 to 0.88356, saving model to /content/checkpoint_entire_best.h5\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.3309 - accuracy: 0.8787 - val_loss: 0.3255 - val_accuracy: 0.8836\n",
            "Epoch 9/150\n",
            "880/882 [============================>.] - ETA: 0s - loss: 0.3182 - accuracy: 0.8812\n",
            "Epoch 00009: val_accuracy improved from 0.88356 to 0.88644, saving model to /content/checkpoint_entire_best.h5\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.3184 - accuracy: 0.8812 - val_loss: 0.3234 - val_accuracy: 0.8864\n",
            "Epoch 10/150\n",
            "879/882 [============================>.] - ETA: 0s - loss: 0.3099 - accuracy: 0.8847\n",
            "Epoch 00010: val_accuracy did not improve from 0.88644\n",
            "882/882 [==============================] - 11s 13ms/step - loss: 0.3100 - accuracy: 0.8847 - val_loss: 0.3310 - val_accuracy: 0.8829\n",
            "Epoch 11/150\n",
            "878/882 [============================>.] - ETA: 0s - loss: 0.3026 - accuracy: 0.8869\n",
            "Epoch 00011: val_accuracy improved from 0.88644 to 0.88729, saving model to /content/checkpoint_entire_best.h5\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.3028 - accuracy: 0.8868 - val_loss: 0.3205 - val_accuracy: 0.8873\n",
            "Epoch 12/150\n",
            "879/882 [============================>.] - ETA: 0s - loss: 0.2981 - accuracy: 0.8884\n",
            "Epoch 00012: val_accuracy did not improve from 0.88729\n",
            "882/882 [==============================] - 11s 13ms/step - loss: 0.2980 - accuracy: 0.8884 - val_loss: 0.3285 - val_accuracy: 0.8855\n",
            "Epoch 13/150\n",
            "882/882 [==============================] - ETA: 0s - loss: 0.2887 - accuracy: 0.8911\n",
            "Epoch 00013: val_accuracy did not improve from 0.88729\n",
            "882/882 [==============================] - 11s 13ms/step - loss: 0.2887 - accuracy: 0.8911 - val_loss: 0.3209 - val_accuracy: 0.8866\n",
            "Epoch 14/150\n",
            "878/882 [============================>.] - ETA: 0s - loss: 0.2836 - accuracy: 0.8917\n",
            "Epoch 00014: val_accuracy improved from 0.88729 to 0.89021, saving model to /content/checkpoint_entire_best.h5\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.2837 - accuracy: 0.8916 - val_loss: 0.3212 - val_accuracy: 0.8902\n",
            "Epoch 15/150\n",
            "880/882 [============================>.] - ETA: 0s - loss: 0.2769 - accuracy: 0.8942\n",
            "Epoch 00015: val_accuracy did not improve from 0.89021\n",
            "882/882 [==============================] - 11s 13ms/step - loss: 0.2770 - accuracy: 0.8942 - val_loss: 0.3341 - val_accuracy: 0.8866\n",
            "Epoch 16/150\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.2733 - accuracy: 0.8951\n",
            "Epoch 00016: val_accuracy did not improve from 0.89021\n",
            "882/882 [==============================] - 11s 13ms/step - loss: 0.2733 - accuracy: 0.8951 - val_loss: 0.3267 - val_accuracy: 0.8898\n",
            "Epoch 17/150\n",
            "878/882 [============================>.] - ETA: 0s - loss: 0.2666 - accuracy: 0.8973\n",
            "Epoch 00017: val_accuracy did not improve from 0.89021\n",
            "882/882 [==============================] - 11s 13ms/step - loss: 0.2667 - accuracy: 0.8973 - val_loss: 0.3262 - val_accuracy: 0.8878\n",
            "Epoch 18/150\n",
            "880/882 [============================>.] - ETA: 0s - loss: 0.2637 - accuracy: 0.8975\n",
            "Epoch 00018: val_accuracy did not improve from 0.89021\n",
            "882/882 [==============================] - 11s 13ms/step - loss: 0.2637 - accuracy: 0.8975 - val_loss: 0.3322 - val_accuracy: 0.8879\n",
            "Epoch 19/150\n",
            "880/882 [============================>.] - ETA: 0s - loss: 0.2590 - accuracy: 0.8994\n",
            "Epoch 00019: val_accuracy improved from 0.89021 to 0.89149, saving model to /content/checkpoint_entire_best.h5\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.2589 - accuracy: 0.8994 - val_loss: 0.3225 - val_accuracy: 0.8915\n",
            "Epoch 20/150\n",
            "880/882 [============================>.] - ETA: 0s - loss: 0.2555 - accuracy: 0.9006\n",
            "Epoch 00020: val_accuracy improved from 0.89149 to 0.89255, saving model to /content/checkpoint_entire_best.h5\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.2554 - accuracy: 0.9006 - val_loss: 0.3202 - val_accuracy: 0.8926\n",
            "Epoch 21/150\n",
            "879/882 [============================>.] - ETA: 0s - loss: 0.2506 - accuracy: 0.9021\n",
            "Epoch 00021: val_accuracy did not improve from 0.89255\n",
            "882/882 [==============================] - 11s 13ms/step - loss: 0.2505 - accuracy: 0.9021 - val_loss: 0.3342 - val_accuracy: 0.8923\n",
            "Epoch 22/150\n",
            "878/882 [============================>.] - ETA: 0s - loss: 0.2484 - accuracy: 0.9017\n",
            "Epoch 00022: val_accuracy did not improve from 0.89255\n",
            "882/882 [==============================] - 11s 13ms/step - loss: 0.2484 - accuracy: 0.9017 - val_loss: 0.3246 - val_accuracy: 0.8913\n",
            "Epoch 23/150\n",
            "880/882 [============================>.] - ETA: 0s - loss: 0.2430 - accuracy: 0.9036\n",
            "Epoch 00023: val_accuracy did not improve from 0.89255\n",
            "882/882 [==============================] - 11s 13ms/step - loss: 0.2430 - accuracy: 0.9036 - val_loss: 0.3299 - val_accuracy: 0.8914\n",
            "Epoch 24/150\n",
            "879/882 [============================>.] - ETA: 0s - loss: 0.2403 - accuracy: 0.9049\n",
            "Epoch 00024: val_accuracy did not improve from 0.89255\n",
            "882/882 [==============================] - 11s 13ms/step - loss: 0.2404 - accuracy: 0.9049 - val_loss: 0.3378 - val_accuracy: 0.8869\n",
            "Epoch 25/150\n",
            "878/882 [============================>.] - ETA: 0s - loss: 0.2368 - accuracy: 0.9055\n",
            "Epoch 00025: val_accuracy did not improve from 0.89255\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.2369 - accuracy: 0.9056 - val_loss: 0.3341 - val_accuracy: 0.8888\n",
            "Epoch 26/150\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.2346 - accuracy: 0.9066\n",
            "Epoch 00026: val_accuracy did not improve from 0.89255\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.2345 - accuracy: 0.9066 - val_loss: 0.3354 - val_accuracy: 0.8888\n",
            "Epoch 27/150\n",
            "878/882 [============================>.] - ETA: 0s - loss: 0.2334 - accuracy: 0.9068\n",
            "Epoch 00027: val_accuracy did not improve from 0.89255\n",
            "882/882 [==============================] - 11s 13ms/step - loss: 0.2335 - accuracy: 0.9068 - val_loss: 0.3344 - val_accuracy: 0.8910\n",
            "Epoch 28/150\n",
            "880/882 [============================>.] - ETA: 0s - loss: 0.2298 - accuracy: 0.9089\n",
            "Epoch 00028: val_accuracy did not improve from 0.89255\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.2299 - accuracy: 0.9089 - val_loss: 0.3274 - val_accuracy: 0.8918\n",
            "Epoch 29/150\n",
            "882/882 [==============================] - ETA: 0s - loss: 0.2269 - accuracy: 0.9083\n",
            "Epoch 00029: val_accuracy did not improve from 0.89255\n",
            "882/882 [==============================] - 12s 14ms/step - loss: 0.2269 - accuracy: 0.9083 - val_loss: 0.3308 - val_accuracy: 0.8909\n",
            "Epoch 30/150\n",
            "878/882 [============================>.] - ETA: 0s - loss: 0.2242 - accuracy: 0.9099\n",
            "Epoch 00030: val_accuracy did not improve from 0.89255\n",
            "882/882 [==============================] - 11s 13ms/step - loss: 0.2245 - accuracy: 0.9098 - val_loss: 0.3222 - val_accuracy: 0.8920\n",
            "Epoch 31/150\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.2217 - accuracy: 0.9114\n",
            "Epoch 00031: val_accuracy did not improve from 0.89255\n",
            "882/882 [==============================] - 11s 13ms/step - loss: 0.2217 - accuracy: 0.9114 - val_loss: 0.3388 - val_accuracy: 0.8894\n",
            "Epoch 32/150\n",
            "878/882 [============================>.] - ETA: 0s - loss: 0.2214 - accuracy: 0.9097\n",
            "Epoch 00032: val_accuracy did not improve from 0.89255\n",
            "882/882 [==============================] - 11s 13ms/step - loss: 0.2213 - accuracy: 0.9097 - val_loss: 0.3286 - val_accuracy: 0.8897\n",
            "Epoch 33/150\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.2192 - accuracy: 0.9111\n",
            "Epoch 00033: val_accuracy improved from 0.89255 to 0.89324, saving model to /content/checkpoint_entire_best.h5\n",
            "882/882 [==============================] - 11s 13ms/step - loss: 0.2192 - accuracy: 0.9111 - val_loss: 0.3336 - val_accuracy: 0.8932\n",
            "Epoch 34/150\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.2160 - accuracy: 0.9117\n",
            "Epoch 00034: val_accuracy did not improve from 0.89324\n",
            "882/882 [==============================] - 11s 13ms/step - loss: 0.2160 - accuracy: 0.9117 - val_loss: 0.3474 - val_accuracy: 0.8923\n",
            "Epoch 35/150\n",
            "878/882 [============================>.] - ETA: 0s - loss: 0.2134 - accuracy: 0.9134\n",
            "Epoch 00035: val_accuracy did not improve from 0.89324\n",
            "882/882 [==============================] - 11s 13ms/step - loss: 0.2135 - accuracy: 0.9134 - val_loss: 0.3335 - val_accuracy: 0.8929\n",
            "Epoch 36/150\n",
            "879/882 [============================>.] - ETA: 0s - loss: 0.2112 - accuracy: 0.9132\n",
            "Epoch 00036: val_accuracy did not improve from 0.89324\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.2113 - accuracy: 0.9131 - val_loss: 0.3366 - val_accuracy: 0.8916\n",
            "Epoch 37/150\n",
            "880/882 [============================>.] - ETA: 0s - loss: 0.2101 - accuracy: 0.9149\n",
            "Epoch 00037: val_accuracy did not improve from 0.89324\n",
            "882/882 [==============================] - 11s 13ms/step - loss: 0.2101 - accuracy: 0.9149 - val_loss: 0.3334 - val_accuracy: 0.8927\n",
            "Epoch 38/150\n",
            "878/882 [============================>.] - ETA: 0s - loss: 0.2074 - accuracy: 0.9148\n",
            "Epoch 00038: val_accuracy did not improve from 0.89324\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.2074 - accuracy: 0.9147 - val_loss: 0.3387 - val_accuracy: 0.8929\n",
            "Epoch 39/150\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.2046 - accuracy: 0.9156\n",
            "Epoch 00039: val_accuracy did not improve from 0.89324\n",
            "882/882 [==============================] - 11s 13ms/step - loss: 0.2047 - accuracy: 0.9156 - val_loss: 0.3584 - val_accuracy: 0.8924\n",
            "Epoch 40/150\n",
            "880/882 [============================>.] - ETA: 0s - loss: 0.2049 - accuracy: 0.9164\n",
            "Epoch 00040: val_accuracy did not improve from 0.89324\n",
            "882/882 [==============================] - 11s 13ms/step - loss: 0.2048 - accuracy: 0.9164 - val_loss: 0.3422 - val_accuracy: 0.8932\n",
            "Epoch 41/150\n",
            "878/882 [============================>.] - ETA: 0s - loss: 0.2031 - accuracy: 0.9157\n",
            "Epoch 00041: val_accuracy did not improve from 0.89324\n",
            "882/882 [==============================] - 11s 13ms/step - loss: 0.2031 - accuracy: 0.9157 - val_loss: 0.3455 - val_accuracy: 0.8931\n",
            "Epoch 42/150\n",
            "878/882 [============================>.] - ETA: 0s - loss: 0.2029 - accuracy: 0.9166\n",
            "Epoch 00042: val_accuracy improved from 0.89324 to 0.89410, saving model to /content/checkpoint_entire_best.h5\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.2029 - accuracy: 0.9166 - val_loss: 0.3488 - val_accuracy: 0.8941\n",
            "Epoch 43/150\n",
            "880/882 [============================>.] - ETA: 0s - loss: 0.1994 - accuracy: 0.9181\n",
            "Epoch 00043: val_accuracy improved from 0.89410 to 0.89606, saving model to /content/checkpoint_entire_best.h5\n",
            "882/882 [==============================] - 11s 13ms/step - loss: 0.1994 - accuracy: 0.9181 - val_loss: 0.3592 - val_accuracy: 0.8961\n",
            "Epoch 44/150\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.1991 - accuracy: 0.9179\n",
            "Epoch 00044: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 11s 13ms/step - loss: 0.1991 - accuracy: 0.9179 - val_loss: 0.3501 - val_accuracy: 0.8929\n",
            "Epoch 45/150\n",
            "882/882 [==============================] - ETA: 0s - loss: 0.1968 - accuracy: 0.9195\n",
            "Epoch 00045: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 11s 13ms/step - loss: 0.1968 - accuracy: 0.9195 - val_loss: 0.3582 - val_accuracy: 0.8937\n",
            "Epoch 46/150\n",
            "878/882 [============================>.] - ETA: 0s - loss: 0.1955 - accuracy: 0.9191\n",
            "Epoch 00046: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 11s 13ms/step - loss: 0.1955 - accuracy: 0.9191 - val_loss: 0.3616 - val_accuracy: 0.8948\n",
            "Epoch 47/150\n",
            "878/882 [============================>.] - ETA: 0s - loss: 0.1947 - accuracy: 0.9192\n",
            "Epoch 00047: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 11s 13ms/step - loss: 0.1946 - accuracy: 0.9192 - val_loss: 0.3494 - val_accuracy: 0.8944\n",
            "Epoch 48/150\n",
            "880/882 [============================>.] - ETA: 0s - loss: 0.1930 - accuracy: 0.9199\n",
            "Epoch 00048: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 11s 13ms/step - loss: 0.1931 - accuracy: 0.9199 - val_loss: 0.3648 - val_accuracy: 0.8919\n",
            "Epoch 49/150\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.1903 - accuracy: 0.9210\n",
            "Epoch 00049: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 11s 13ms/step - loss: 0.1903 - accuracy: 0.9211 - val_loss: 0.3606 - val_accuracy: 0.8937\n",
            "Epoch 50/150\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.1921 - accuracy: 0.9202\n",
            "Epoch 00050: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 11s 13ms/step - loss: 0.1921 - accuracy: 0.9202 - val_loss: 0.3569 - val_accuracy: 0.8922\n",
            "Epoch 51/150\n",
            "878/882 [============================>.] - ETA: 0s - loss: 0.1880 - accuracy: 0.9221\n",
            "Epoch 00051: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 11s 13ms/step - loss: 0.1881 - accuracy: 0.9220 - val_loss: 0.3697 - val_accuracy: 0.8941\n",
            "Epoch 52/150\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.1874 - accuracy: 0.9221\n",
            "Epoch 00052: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1873 - accuracy: 0.9221 - val_loss: 0.3572 - val_accuracy: 0.8921\n",
            "Epoch 53/150\n",
            "879/882 [============================>.] - ETA: 0s - loss: 0.1864 - accuracy: 0.9221\n",
            "Epoch 00053: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 11s 13ms/step - loss: 0.1864 - accuracy: 0.9221 - val_loss: 0.3594 - val_accuracy: 0.8927\n",
            "Epoch 54/150\n",
            "879/882 [============================>.] - ETA: 0s - loss: 0.1847 - accuracy: 0.9225\n",
            "Epoch 00054: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 11s 13ms/step - loss: 0.1847 - accuracy: 0.9225 - val_loss: 0.3780 - val_accuracy: 0.8941\n",
            "Epoch 55/150\n",
            "879/882 [============================>.] - ETA: 0s - loss: 0.1853 - accuracy: 0.9238\n",
            "Epoch 00055: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 13s 15ms/step - loss: 0.1854 - accuracy: 0.9238 - val_loss: 0.3612 - val_accuracy: 0.8945\n",
            "Epoch 56/150\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.1821 - accuracy: 0.9246\n",
            "Epoch 00056: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 14ms/step - loss: 0.1821 - accuracy: 0.9246 - val_loss: 0.3636 - val_accuracy: 0.8936\n",
            "Epoch 57/150\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.1805 - accuracy: 0.9247\n",
            "Epoch 00057: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1805 - accuracy: 0.9247 - val_loss: 0.3593 - val_accuracy: 0.8933\n",
            "Epoch 58/150\n",
            "880/882 [============================>.] - ETA: 0s - loss: 0.1805 - accuracy: 0.9250\n",
            "Epoch 00058: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 11s 13ms/step - loss: 0.1805 - accuracy: 0.9250 - val_loss: 0.3697 - val_accuracy: 0.8923\n",
            "Epoch 59/150\n",
            "879/882 [============================>.] - ETA: 0s - loss: 0.1801 - accuracy: 0.9244\n",
            "Epoch 00059: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1802 - accuracy: 0.9244 - val_loss: 0.3684 - val_accuracy: 0.8932\n",
            "Epoch 60/150\n",
            "879/882 [============================>.] - ETA: 0s - loss: 0.1779 - accuracy: 0.9257\n",
            "Epoch 00060: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1778 - accuracy: 0.9257 - val_loss: 0.3731 - val_accuracy: 0.8949\n",
            "Epoch 61/150\n",
            "880/882 [============================>.] - ETA: 0s - loss: 0.1769 - accuracy: 0.9256\n",
            "Epoch 00061: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1769 - accuracy: 0.9255 - val_loss: 0.3701 - val_accuracy: 0.8914\n",
            "Epoch 62/150\n",
            "878/882 [============================>.] - ETA: 0s - loss: 0.1774 - accuracy: 0.9265\n",
            "Epoch 00062: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1774 - accuracy: 0.9265 - val_loss: 0.3844 - val_accuracy: 0.8911\n",
            "Epoch 63/150\n",
            "880/882 [============================>.] - ETA: 0s - loss: 0.1765 - accuracy: 0.9269\n",
            "Epoch 00063: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1764 - accuracy: 0.9269 - val_loss: 0.3640 - val_accuracy: 0.8913\n",
            "Epoch 64/150\n",
            "879/882 [============================>.] - ETA: 0s - loss: 0.1749 - accuracy: 0.9262\n",
            "Epoch 00064: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1749 - accuracy: 0.9262 - val_loss: 0.3741 - val_accuracy: 0.8919\n",
            "Epoch 65/150\n",
            "879/882 [============================>.] - ETA: 0s - loss: 0.1745 - accuracy: 0.9268\n",
            "Epoch 00065: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1744 - accuracy: 0.9268 - val_loss: 0.3759 - val_accuracy: 0.8940\n",
            "Epoch 66/150\n",
            "879/882 [============================>.] - ETA: 0s - loss: 0.1737 - accuracy: 0.9272\n",
            "Epoch 00066: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1738 - accuracy: 0.9272 - val_loss: 0.3811 - val_accuracy: 0.8923\n",
            "Epoch 67/150\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.1732 - accuracy: 0.9274\n",
            "Epoch 00067: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1733 - accuracy: 0.9274 - val_loss: 0.3788 - val_accuracy: 0.8893\n",
            "Epoch 68/150\n",
            "880/882 [============================>.] - ETA: 0s - loss: 0.1719 - accuracy: 0.9281\n",
            "Epoch 00068: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1718 - accuracy: 0.9281 - val_loss: 0.3878 - val_accuracy: 0.8927\n",
            "Epoch 69/150\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.1693 - accuracy: 0.9283\n",
            "Epoch 00069: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1693 - accuracy: 0.9283 - val_loss: 0.3867 - val_accuracy: 0.8928\n",
            "Epoch 70/150\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.1700 - accuracy: 0.9284\n",
            "Epoch 00070: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1700 - accuracy: 0.9284 - val_loss: 0.3938 - val_accuracy: 0.8944\n",
            "Epoch 71/150\n",
            "880/882 [============================>.] - ETA: 0s - loss: 0.1705 - accuracy: 0.9290\n",
            "Epoch 00071: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1705 - accuracy: 0.9290 - val_loss: 0.3923 - val_accuracy: 0.8939\n",
            "Epoch 72/150\n",
            "878/882 [============================>.] - ETA: 0s - loss: 0.1681 - accuracy: 0.9285\n",
            "Epoch 00072: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1682 - accuracy: 0.9285 - val_loss: 0.3937 - val_accuracy: 0.8934\n",
            "Epoch 73/150\n",
            "880/882 [============================>.] - ETA: 0s - loss: 0.1693 - accuracy: 0.9291\n",
            "Epoch 00073: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1692 - accuracy: 0.9291 - val_loss: 0.3783 - val_accuracy: 0.8914\n",
            "Epoch 74/150\n",
            "880/882 [============================>.] - ETA: 0s - loss: 0.1657 - accuracy: 0.9301\n",
            "Epoch 00074: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1657 - accuracy: 0.9301 - val_loss: 0.3911 - val_accuracy: 0.8941\n",
            "Epoch 75/150\n",
            "878/882 [============================>.] - ETA: 0s - loss: 0.1648 - accuracy: 0.9311\n",
            "Epoch 00075: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1648 - accuracy: 0.9311 - val_loss: 0.3954 - val_accuracy: 0.8941\n",
            "Epoch 76/150\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.1667 - accuracy: 0.9300\n",
            "Epoch 00076: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1667 - accuracy: 0.9300 - val_loss: 0.3942 - val_accuracy: 0.8925\n",
            "Epoch 77/150\n",
            "882/882 [==============================] - ETA: 0s - loss: 0.1645 - accuracy: 0.9307\n",
            "Epoch 00077: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1645 - accuracy: 0.9307 - val_loss: 0.3987 - val_accuracy: 0.8902\n",
            "Epoch 78/150\n",
            "880/882 [============================>.] - ETA: 0s - loss: 0.1641 - accuracy: 0.9310\n",
            "Epoch 00078: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1641 - accuracy: 0.9310 - val_loss: 0.3908 - val_accuracy: 0.8922\n",
            "Epoch 79/150\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.1637 - accuracy: 0.9304\n",
            "Epoch 00079: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1638 - accuracy: 0.9304 - val_loss: 0.3904 - val_accuracy: 0.8914\n",
            "Epoch 80/150\n",
            "880/882 [============================>.] - ETA: 0s - loss: 0.1638 - accuracy: 0.9318\n",
            "Epoch 00080: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1638 - accuracy: 0.9319 - val_loss: 0.4023 - val_accuracy: 0.8898\n",
            "Epoch 81/150\n",
            "882/882 [==============================] - ETA: 0s - loss: 0.1633 - accuracy: 0.9312\n",
            "Epoch 00081: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1633 - accuracy: 0.9312 - val_loss: 0.4106 - val_accuracy: 0.8912\n",
            "Epoch 82/150\n",
            "878/882 [============================>.] - ETA: 0s - loss: 0.1622 - accuracy: 0.9316\n",
            "Epoch 00082: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1623 - accuracy: 0.9316 - val_loss: 0.4069 - val_accuracy: 0.8899\n",
            "Epoch 83/150\n",
            "879/882 [============================>.] - ETA: 0s - loss: 0.1615 - accuracy: 0.9323\n",
            "Epoch 00083: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1616 - accuracy: 0.9322 - val_loss: 0.4087 - val_accuracy: 0.8924\n",
            "Epoch 84/150\n",
            "878/882 [============================>.] - ETA: 0s - loss: 0.1624 - accuracy: 0.9320\n",
            "Epoch 00084: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1625 - accuracy: 0.9320 - val_loss: 0.4135 - val_accuracy: 0.8920\n",
            "Epoch 85/150\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.1597 - accuracy: 0.9327\n",
            "Epoch 00085: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1597 - accuracy: 0.9327 - val_loss: 0.4163 - val_accuracy: 0.8918\n",
            "Epoch 86/150\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.1603 - accuracy: 0.9324\n",
            "Epoch 00086: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1603 - accuracy: 0.9324 - val_loss: 0.4100 - val_accuracy: 0.8926\n",
            "Epoch 87/150\n",
            "879/882 [============================>.] - ETA: 0s - loss: 0.1595 - accuracy: 0.9336\n",
            "Epoch 00087: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 11s 13ms/step - loss: 0.1595 - accuracy: 0.9336 - val_loss: 0.4148 - val_accuracy: 0.8909\n",
            "Epoch 88/150\n",
            "878/882 [============================>.] - ETA: 0s - loss: 0.1583 - accuracy: 0.9334\n",
            "Epoch 00088: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1584 - accuracy: 0.9334 - val_loss: 0.4173 - val_accuracy: 0.8883\n",
            "Epoch 89/150\n",
            "878/882 [============================>.] - ETA: 0s - loss: 0.1580 - accuracy: 0.9339\n",
            "Epoch 00089: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1580 - accuracy: 0.9339 - val_loss: 0.4049 - val_accuracy: 0.8923\n",
            "Epoch 90/150\n",
            "878/882 [============================>.] - ETA: 0s - loss: 0.1551 - accuracy: 0.9345\n",
            "Epoch 00090: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1552 - accuracy: 0.9344 - val_loss: 0.4237 - val_accuracy: 0.8927\n",
            "Epoch 91/150\n",
            "879/882 [============================>.] - ETA: 0s - loss: 0.1570 - accuracy: 0.9332\n",
            "Epoch 00091: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1571 - accuracy: 0.9331 - val_loss: 0.4243 - val_accuracy: 0.8910\n",
            "Epoch 92/150\n",
            "878/882 [============================>.] - ETA: 0s - loss: 0.1563 - accuracy: 0.9343\n",
            "Epoch 00092: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1564 - accuracy: 0.9343 - val_loss: 0.4258 - val_accuracy: 0.8902\n",
            "Epoch 93/150\n",
            "880/882 [============================>.] - ETA: 0s - loss: 0.1566 - accuracy: 0.9338\n",
            "Epoch 00093: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1566 - accuracy: 0.9338 - val_loss: 0.4149 - val_accuracy: 0.8903\n",
            "Epoch 94/150\n",
            "879/882 [============================>.] - ETA: 0s - loss: 0.1559 - accuracy: 0.9355\n",
            "Epoch 00094: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1559 - accuracy: 0.9355 - val_loss: 0.4257 - val_accuracy: 0.8896\n",
            "Epoch 95/150\n",
            "879/882 [============================>.] - ETA: 0s - loss: 0.1556 - accuracy: 0.9344\n",
            "Epoch 00095: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1555 - accuracy: 0.9345 - val_loss: 0.4378 - val_accuracy: 0.8913\n",
            "Epoch 96/150\n",
            "880/882 [============================>.] - ETA: 0s - loss: 0.1527 - accuracy: 0.9361\n",
            "Epoch 00096: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1527 - accuracy: 0.9361 - val_loss: 0.4325 - val_accuracy: 0.8905\n",
            "Epoch 97/150\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.1542 - accuracy: 0.9346\n",
            "Epoch 00097: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1543 - accuracy: 0.9346 - val_loss: 0.4156 - val_accuracy: 0.8928\n",
            "Epoch 98/150\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.1526 - accuracy: 0.9356\n",
            "Epoch 00098: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1526 - accuracy: 0.9356 - val_loss: 0.4400 - val_accuracy: 0.8920\n",
            "Epoch 99/150\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.1543 - accuracy: 0.9343\n",
            "Epoch 00099: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1543 - accuracy: 0.9343 - val_loss: 0.4127 - val_accuracy: 0.8903\n",
            "Epoch 100/150\n",
            "880/882 [============================>.] - ETA: 0s - loss: 0.1523 - accuracy: 0.9365\n",
            "Epoch 00100: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1522 - accuracy: 0.9366 - val_loss: 0.4335 - val_accuracy: 0.8903\n",
            "Epoch 101/150\n",
            "879/882 [============================>.] - ETA: 0s - loss: 0.1501 - accuracy: 0.9369\n",
            "Epoch 00101: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1501 - accuracy: 0.9369 - val_loss: 0.4668 - val_accuracy: 0.8909\n",
            "Epoch 102/150\n",
            "880/882 [============================>.] - ETA: 0s - loss: 0.1518 - accuracy: 0.9365\n",
            "Epoch 00102: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1518 - accuracy: 0.9365 - val_loss: 0.4369 - val_accuracy: 0.8917\n",
            "Epoch 103/150\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.1509 - accuracy: 0.9371\n",
            "Epoch 00103: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1509 - accuracy: 0.9371 - val_loss: 0.4340 - val_accuracy: 0.8910\n",
            "Epoch 104/150\n",
            "880/882 [============================>.] - ETA: 0s - loss: 0.1530 - accuracy: 0.9352\n",
            "Epoch 00104: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1531 - accuracy: 0.9352 - val_loss: 0.4255 - val_accuracy: 0.8933\n",
            "Epoch 105/150\n",
            "879/882 [============================>.] - ETA: 0s - loss: 0.1491 - accuracy: 0.9369\n",
            "Epoch 00105: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1490 - accuracy: 0.9369 - val_loss: 0.4414 - val_accuracy: 0.8911\n",
            "Epoch 106/150\n",
            "880/882 [============================>.] - ETA: 0s - loss: 0.1502 - accuracy: 0.9371\n",
            "Epoch 00106: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1502 - accuracy: 0.9371 - val_loss: 0.4287 - val_accuracy: 0.8898\n",
            "Epoch 107/150\n",
            "879/882 [============================>.] - ETA: 0s - loss: 0.1504 - accuracy: 0.9373\n",
            "Epoch 00107: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1506 - accuracy: 0.9373 - val_loss: 0.4280 - val_accuracy: 0.8909\n",
            "Epoch 108/150\n",
            "882/882 [==============================] - ETA: 0s - loss: 0.1491 - accuracy: 0.9376\n",
            "Epoch 00108: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1491 - accuracy: 0.9376 - val_loss: 0.4453 - val_accuracy: 0.8903\n",
            "Epoch 109/150\n",
            "878/882 [============================>.] - ETA: 0s - loss: 0.1479 - accuracy: 0.9383\n",
            "Epoch 00109: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1479 - accuracy: 0.9383 - val_loss: 0.4330 - val_accuracy: 0.8932\n",
            "Epoch 110/150\n",
            "879/882 [============================>.] - ETA: 0s - loss: 0.1479 - accuracy: 0.9376\n",
            "Epoch 00110: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1479 - accuracy: 0.9376 - val_loss: 0.4443 - val_accuracy: 0.8909\n",
            "Epoch 111/150\n",
            "882/882 [==============================] - ETA: 0s - loss: 0.1475 - accuracy: 0.9387\n",
            "Epoch 00111: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1475 - accuracy: 0.9387 - val_loss: 0.4476 - val_accuracy: 0.8917\n",
            "Epoch 112/150\n",
            "878/882 [============================>.] - ETA: 0s - loss: 0.1483 - accuracy: 0.9379\n",
            "Epoch 00112: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1482 - accuracy: 0.9379 - val_loss: 0.4347 - val_accuracy: 0.8897\n",
            "Epoch 113/150\n",
            "880/882 [============================>.] - ETA: 0s - loss: 0.1495 - accuracy: 0.9377\n",
            "Epoch 00113: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1495 - accuracy: 0.9377 - val_loss: 0.4341 - val_accuracy: 0.8911\n",
            "Epoch 114/150\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.1466 - accuracy: 0.9376\n",
            "Epoch 00114: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1466 - accuracy: 0.9376 - val_loss: 0.4491 - val_accuracy: 0.8916\n",
            "Epoch 115/150\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.1458 - accuracy: 0.9392\n",
            "Epoch 00115: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1458 - accuracy: 0.9392 - val_loss: 0.4395 - val_accuracy: 0.8900\n",
            "Epoch 116/150\n",
            "880/882 [============================>.] - ETA: 0s - loss: 0.1459 - accuracy: 0.9393\n",
            "Epoch 00116: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1458 - accuracy: 0.9394 - val_loss: 0.4448 - val_accuracy: 0.8921\n",
            "Epoch 117/150\n",
            "879/882 [============================>.] - ETA: 0s - loss: 0.1473 - accuracy: 0.9381\n",
            "Epoch 00117: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1473 - accuracy: 0.9381 - val_loss: 0.4340 - val_accuracy: 0.8914\n",
            "Epoch 118/150\n",
            "882/882 [==============================] - ETA: 0s - loss: 0.1448 - accuracy: 0.9385\n",
            "Epoch 00118: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1448 - accuracy: 0.9385 - val_loss: 0.4523 - val_accuracy: 0.8918\n",
            "Epoch 119/150\n",
            "878/882 [============================>.] - ETA: 0s - loss: 0.1460 - accuracy: 0.9390\n",
            "Epoch 00119: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1461 - accuracy: 0.9390 - val_loss: 0.4481 - val_accuracy: 0.8897\n",
            "Epoch 120/150\n",
            "882/882 [==============================] - ETA: 0s - loss: 0.1425 - accuracy: 0.9404\n",
            "Epoch 00120: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1425 - accuracy: 0.9404 - val_loss: 0.4601 - val_accuracy: 0.8888\n",
            "Epoch 121/150\n",
            "880/882 [============================>.] - ETA: 0s - loss: 0.1419 - accuracy: 0.9406\n",
            "Epoch 00121: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1419 - accuracy: 0.9406 - val_loss: 0.4662 - val_accuracy: 0.8910\n",
            "Epoch 122/150\n",
            "880/882 [============================>.] - ETA: 0s - loss: 0.1449 - accuracy: 0.9392\n",
            "Epoch 00122: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1449 - accuracy: 0.9392 - val_loss: 0.4453 - val_accuracy: 0.8915\n",
            "Epoch 123/150\n",
            "879/882 [============================>.] - ETA: 0s - loss: 0.1459 - accuracy: 0.9392\n",
            "Epoch 00123: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1460 - accuracy: 0.9392 - val_loss: 0.4504 - val_accuracy: 0.8920\n",
            "Epoch 124/150\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.1413 - accuracy: 0.9405\n",
            "Epoch 00124: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1413 - accuracy: 0.9405 - val_loss: 0.4582 - val_accuracy: 0.8915\n",
            "Epoch 125/150\n",
            "880/882 [============================>.] - ETA: 0s - loss: 0.1427 - accuracy: 0.9405\n",
            "Epoch 00125: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1428 - accuracy: 0.9405 - val_loss: 0.4493 - val_accuracy: 0.8890\n",
            "Epoch 126/150\n",
            "879/882 [============================>.] - ETA: 0s - loss: 0.1409 - accuracy: 0.9407\n",
            "Epoch 00126: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1408 - accuracy: 0.9408 - val_loss: 0.4705 - val_accuracy: 0.8911\n",
            "Epoch 127/150\n",
            "880/882 [============================>.] - ETA: 0s - loss: 0.1430 - accuracy: 0.9400\n",
            "Epoch 00127: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1431 - accuracy: 0.9400 - val_loss: 0.4582 - val_accuracy: 0.8888\n",
            "Epoch 128/150\n",
            "879/882 [============================>.] - ETA: 0s - loss: 0.1416 - accuracy: 0.9411\n",
            "Epoch 00128: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1415 - accuracy: 0.9411 - val_loss: 0.4598 - val_accuracy: 0.8900\n",
            "Epoch 129/150\n",
            "879/882 [============================>.] - ETA: 0s - loss: 0.1411 - accuracy: 0.9403\n",
            "Epoch 00129: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1411 - accuracy: 0.9403 - val_loss: 0.4441 - val_accuracy: 0.8877\n",
            "Epoch 130/150\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.1428 - accuracy: 0.9405\n",
            "Epoch 00130: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1428 - accuracy: 0.9405 - val_loss: 0.4621 - val_accuracy: 0.8881\n",
            "Epoch 131/150\n",
            "880/882 [============================>.] - ETA: 0s - loss: 0.1414 - accuracy: 0.9406\n",
            "Epoch 00131: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1414 - accuracy: 0.9406 - val_loss: 0.4460 - val_accuracy: 0.8874\n",
            "Epoch 132/150\n",
            "882/882 [==============================] - ETA: 0s - loss: 0.1403 - accuracy: 0.9412\n",
            "Epoch 00132: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1403 - accuracy: 0.9412 - val_loss: 0.4704 - val_accuracy: 0.8869\n",
            "Epoch 133/150\n",
            "879/882 [============================>.] - ETA: 0s - loss: 0.1406 - accuracy: 0.9413\n",
            "Epoch 00133: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1406 - accuracy: 0.9412 - val_loss: 0.4651 - val_accuracy: 0.8883\n",
            "Epoch 134/150\n",
            "878/882 [============================>.] - ETA: 0s - loss: 0.1404 - accuracy: 0.9421\n",
            "Epoch 00134: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1405 - accuracy: 0.9421 - val_loss: 0.4786 - val_accuracy: 0.8902\n",
            "Epoch 135/150\n",
            "879/882 [============================>.] - ETA: 0s - loss: 0.1408 - accuracy: 0.9419\n",
            "Epoch 00135: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1409 - accuracy: 0.9418 - val_loss: 0.4807 - val_accuracy: 0.8915\n",
            "Epoch 136/150\n",
            "880/882 [============================>.] - ETA: 0s - loss: 0.1389 - accuracy: 0.9416\n",
            "Epoch 00136: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 14ms/step - loss: 0.1390 - accuracy: 0.9415 - val_loss: 0.4750 - val_accuracy: 0.8901\n",
            "Epoch 137/150\n",
            "878/882 [============================>.] - ETA: 0s - loss: 0.1388 - accuracy: 0.9421\n",
            "Epoch 00137: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1389 - accuracy: 0.9420 - val_loss: 0.4750 - val_accuracy: 0.8904\n",
            "Epoch 138/150\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.1410 - accuracy: 0.9414\n",
            "Epoch 00138: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1410 - accuracy: 0.9414 - val_loss: 0.4639 - val_accuracy: 0.8901\n",
            "Epoch 139/150\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.1369 - accuracy: 0.9433\n",
            "Epoch 00139: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1369 - accuracy: 0.9433 - val_loss: 0.4908 - val_accuracy: 0.8916\n",
            "Epoch 140/150\n",
            "882/882 [==============================] - ETA: 0s - loss: 0.1390 - accuracy: 0.9423\n",
            "Epoch 00140: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1390 - accuracy: 0.9423 - val_loss: 0.4731 - val_accuracy: 0.8914\n",
            "Epoch 141/150\n",
            "882/882 [==============================] - ETA: 0s - loss: 0.1372 - accuracy: 0.9427\n",
            "Epoch 00141: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1372 - accuracy: 0.9427 - val_loss: 0.4878 - val_accuracy: 0.8887\n",
            "Epoch 142/150\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.1367 - accuracy: 0.9427\n",
            "Epoch 00142: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1367 - accuracy: 0.9427 - val_loss: 0.4841 - val_accuracy: 0.8898\n",
            "Epoch 143/150\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.1404 - accuracy: 0.9412\n",
            "Epoch 00143: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 11s 13ms/step - loss: 0.1403 - accuracy: 0.9412 - val_loss: 0.4852 - val_accuracy: 0.8908\n",
            "Epoch 144/150\n",
            "878/882 [============================>.] - ETA: 0s - loss: 0.1369 - accuracy: 0.9425\n",
            "Epoch 00144: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1369 - accuracy: 0.9425 - val_loss: 0.4623 - val_accuracy: 0.8885\n",
            "Epoch 145/150\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.1376 - accuracy: 0.9426\n",
            "Epoch 00145: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1375 - accuracy: 0.9426 - val_loss: 0.4839 - val_accuracy: 0.8899\n",
            "Epoch 146/150\n",
            "882/882 [==============================] - ETA: 0s - loss: 0.1390 - accuracy: 0.9421\n",
            "Epoch 00146: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1390 - accuracy: 0.9421 - val_loss: 0.4689 - val_accuracy: 0.8886\n",
            "Epoch 147/150\n",
            "880/882 [============================>.] - ETA: 0s - loss: 0.1368 - accuracy: 0.9427\n",
            "Epoch 00147: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 11s 13ms/step - loss: 0.1368 - accuracy: 0.9427 - val_loss: 0.4793 - val_accuracy: 0.8910\n",
            "Epoch 148/150\n",
            "880/882 [============================>.] - ETA: 0s - loss: 0.1382 - accuracy: 0.9429\n",
            "Epoch 00148: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 11s 13ms/step - loss: 0.1382 - accuracy: 0.9428 - val_loss: 0.4723 - val_accuracy: 0.8923\n",
            "Epoch 149/150\n",
            "878/882 [============================>.] - ETA: 0s - loss: 0.1350 - accuracy: 0.9440\n",
            "Epoch 00149: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1351 - accuracy: 0.9439 - val_loss: 0.4645 - val_accuracy: 0.8893\n",
            "Epoch 150/150\n",
            "879/882 [============================>.] - ETA: 0s - loss: 0.1347 - accuracy: 0.9433\n",
            "Epoch 00150: val_accuracy did not improve from 0.89606\n",
            "882/882 [==============================] - 12s 13ms/step - loss: 0.1347 - accuracy: 0.9432 - val_loss: 0.4563 - val_accuracy: 0.8900\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe4e02651d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QR9WUYXxqtfR"
      },
      "source": [
        "# **4. 모델 저장**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Wi9yznz4qvzK",
        "colab": {}
      },
      "source": [
        "save_path = '/content/'\n",
        "team_name = 'team11'\n",
        "\n",
        "# 트레이닝된 전체 모델을 저장합니다.\n",
        "model.save(save_path +  'model_entire_'+ team_name + '.h5')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4aPbgI-c-Kj8"
      },
      "source": [
        "# **5. 모델 로드 및 평가**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y7WONVxH-Kt6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "7b19ab5d-dcb3-4ef6-cecf-8086a6148f68"
      },
      "source": [
        "save_path = '/content/'\n",
        "team_name = 'team11'\n",
        "\n",
        "model = keras.models.load_model(save_path + 'model_entire_' + team_name + '.h5')\n",
        "model.evaluate(x_test_after, y_test)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "588/588 [==============================] - 2s 4ms/step - loss: 0.3592 - accuracy: 0.8961\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.35915133357048035, 0.8960638046264648]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oQ5EVHMF2sV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}